---
title: "CW"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(NbClust)
library(tictoc)
library(beepr)
library(flexclust)
library(corrplot)
library(dendextend)
library(ggplot2)

wine <- read.csv("https://github.com/jaewilson07/Hello-World/raw/master/Data%20Mining%20Coursework/Whitewine.csv")

```

## Explore and Format the imported Wine data
Although the wine dataframe imported properly, the Quality variable is not an ordinal factor as described
-- cast the Quality variable from INT to Factor

Plot counts of wine grouped by Quality to explore the distribution of quality levels.
-- only 7 out of 10 possible levels are (unevenly) represented in our dataset.
-- Assuming that subjective taste quality can be used to distinguish clusters of chemical attributes, there should be at most 7, more likely 5 clusters in our dataset.


```{r formatWine}
#explore the wine dataframe
str(wine)

#Convert the Quality variable into an Ordinal Factor
qual_levels <- c(1:10)
wine$quality	<-factor(wine$quality, levels = qual_levels, ordered = TRUE)

#view the distribution of Quality in the existing dataset
ggplot(wine, aes(x = quality)) +
	geom_bar()


```

## Find a recommendation for cluster sizes
Use NbClust() function and it's 30 indices to find recommendations for number of clusters to use in the k-means algorithm.
-- We'll set our limits for cluster size recommendations at 2 and 7 clusters because given our earlier assumption, there shouldn't be more than 7 clusters.
-- To avoid leaking information about the outcme variable to our algorithm, we'll begin by first isolating the Quality variable from our dataset.
-- Because our chemical property variables are measured on different scales (eg. the range of Acidity is 3.8 : 14.2 while the range of Chlorides is only .009 : .346); we'll scale each variable by taking x - center (the variable mean) / standard deviation of the variable to prevent one variable from more strongly affecting the k-means distancing algorithm.



```{r clusterWine}

#isolate the quality columns
wine_quality <- wine$quality

#scale the data set
wine_train <- wine[,-12]
wine_train <- scale(wine_train)

#find recommendation for best number of clusters
tic()
numClust_wine <- NbClust(wine_train, method = "kmeans", min.nc =  2, max.nc = 7)
beep()
#store duration of NBClust
t_clust<- toc()
t_clust

#numClust_wine$Best.n[1,] stores a list of the number clusters recommended by each index
#find the top two (mode) wine cluster recommendations
topClust_Wine_Rec <- as.numeric(names(sort(-table(numClust_wine$Best.n[1,])))[1:2])
topClust_Wine_Rec

```

## runKmeans
Use kmeans() function to calculate 3 cluster permutations inl 7 (number of Quality levels represented in data) and the two most frequently occuring cluster recommendations.
```{r runKMeans}
paste(
	c("Run k-means using 7, the number of represented Quality groups.  Additionally run k-means with the following cluster sizes"
		, topClust_Wine_Rec[1]
		, topClust_Wine_Rec[2] ), collapse = ", ")

k_wine_10 <- kmeans(wine_train, 7)
k_wine_1 <- kmeans(wine_train, topClust_Wine_Rec[1])
k_wine_2 <- kmeans(wine_train, topClust_Wine_Rec[2])
```

## Analyze results

```{r analyze results}
tbwine <- table(wine[,12])
tb_ct_10 <- table(k_wine_10$cluster, wine[,12])
tb_ct_1 <- table(k_wine_1$cluster, wine[,12])
tb_ct_2 <- table(k_wine_2$cluster, wine[,12])

randIndex(tb_ct_10)
randIndex(tb_ct_1)
randIndex(tb_ct_2)
```


#hclust (agglomerative) single
hclust_sing <- hclust( dist(wine_train), method= "single")
dend_sing <- as.dendrogram(hclust_sing)
#hclust complete
hclust_compl <- hclust( dist(wine_train), method= "complete")
dend_compl <- as.dendrogram(hclust_compl)
#hclustaverage methods
hclust_avg <- hclust( dist(wine_train), method= "average")
dend_avg <- as.dendrogram(hclust_avg)

#Create dendogram visualization of all 3
layout(matrix(c(1:3),1,3))
plot(hclust_sing)
plot(hclust_compl)
plot(hclust_avg)

#create a list of dendgrams
d <- dendlist(
		single = dend_sing,
		complete = dend_compl,
		average = dend_avg)
#cor.dendlist between each clustering result 
cor.dendlist(d)
beep()
#Discuss the produced results after using the coorplot function.

str(hclust_avg)

str()
h<- dendlist(hclust_avg)
=======
install.packages('XLConnect', dependencies =  TRUE) 
require(XLConnect) # load XLConnect package 
require(NbClust)

wk = loadWorkbook("C:\\Users\\onyxr\\Dropbox (Personal)\\School\\UW\\Data Mining\\Data Mining Coursework\\whitewine.xlsx") 
df = readWorksheet(wk, sheet="White Wine")

#head(df)
#str(df)

#convert Quality into an ordinal Factor
qual_levels <- c(1:10)
df$quality	<-factor(df$quality, levels = qual_levels, ordered = TRUE)

#split the wine dataset in half for training and test
wine_train <- df[1:nrow(df)/2, ]
wine_test <-  df[nrow(df)/2:nrow(df), ]

#isolate the quality columns
train_quality <- wine_train$quality
test_quality <- wine_test$quality

#create a function for scaling variables on a 0:1 scale
min_max <- function(x) {
		(x - min(x)) / ( max(x) - min(x))
	}

#apply min_max to each column of the data set
for (i in 1:(ncol(wine_train)-1) ){ wine_train[i] <- min_max(wine_train[i]) }
for (i in 1:(ncol(wine_test)-1) ){ wine_test[i] <- min_max(wine_test[i]) }

for (i in 1:5 { 
	bestClust[i] <- NbClust( sample(wine_train[1:11], 100, replace=FALSE), method = "kmeans", min.nc =  2, max.nc = 15)

})

plot(bestClust$Best)

str(bestClust)



```


```{r}

```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
