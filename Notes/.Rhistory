rename( num = X)
coffee_tweets <- coffee_tweets_df$text
chardonnay_tweets <- chardonnay_tweets_df$text
# Make a vector source (list): coffee_source
coffee_vec_source <- VectorSource(coffee_tweets)
coffee_vec_corpus <- VCorpus(coffee_vec_source)
# Print out coffee_corpus
print(coffee_vec_corpus)
# Print data on the 15th tweet in coffee_corpus
print(coffee_vec_corpus[[15]])
# Print the content of the 15th tweet in coffee_corpus
print(coffee_vec_corpus[[15]][1])
#"@HeatherWhaley I was about 2 joke it takes 2 hands to hold hot coffee...then I read headline! #Don'tDrinkNShoot"
#NOTE:  DataframeSource() will convert entire row into ONE DOCUMENT (retain independent tweets structure)
#NOTE : VectorSource(sample_df) will convert entire sample_df$data1 into one document (combine all variables)
#sample_df <- data.frame( data1 = c("Apples and bananas" , "I think i need to drink coffee"),
# data2 = c( "Pears, plums and peaches", "This is how we suffer through bad classes, #Starbucks" )) %>%
#  VectorSource()
#print(sample_df)
# Make corpus which includes metadata by adding readerControl
coffee_df_corpus <- VCorpus(
DataframeSource(coffee_tweets_df),
readerControl = list(reader = custom_reader)) %>%
clean_corpus_coffee()
chardonnay_df_corpus <- VCorpus(
DataframeSource(chardonnay_tweets_df),
readerControl = list(reader = custom_reader)) %>%
clean_corpus_chardonnay()
# Print data
#str coffee_corpus
# NOTE: syntax for selecting one liste item
str(coffee_df_corpus[[1]])
print(coffee_df_corpus[[1]][1])
print(coffee_df_corpus[[1]][2])
##DTM vs TDM simply transposes the length / width of the resulting matrix
(coffee_df_dtm <- DocumentTermMatrix(coffee_df_corpus))
coffee_m_dtm <- as.matrix(coffee_df_dtm)
View(coffee_df_corpus)
custom_reader <- readTabular(mapping = list(content = "text",
id = "num",
author = "screenName",
date = "created"))
coffee_tweets_df<- read.csv("https://raw.githubusercontent.com/jaewilson07/Hello-World/master/Datasets/DataCamp/CoffeeTweets.txt",
stringsAsFactors = FALSE)
coffee_corpus <- VCorpus( DataframeSource(coffee_tweets_df) ,
readerControl = list(reader = custom_reader))
coffee_tdm <- TermDocumentMatrix(coffee_corpus) %>%
as.matrix()
dim(coffee_tdm)
coffee_words <- data.frame("word"  = rownames(coffee_tdm),
"freq" = rowSums(coffee_tdm)
)
library(dplyr)
library(tidytext)
library(qdap)
library(tm)
library(beepr)
custom_reader <- readTabular(mapping = list(content = "text",
id = "num",
author = "screenName",
date = "created"))
#install.packages("tm")
coffee_tweets_df<- read.csv("https://raw.githubusercontent.com/jaewilson07/Hello-World/master/Datasets/DataCamp/CoffeeTweets.txt",
stringsAsFactors = FALSE)
coffee_corpus <- VCorpus( DataframeSource(coffee_tweets_df) ,
readerControl = list(reader = custom_reader))
coffee_tdm <- TermDocumentMatrix(coffee_corpus) %>%
as.matrix()
dim(coffee_tdm)
#create aa dataframe of words and frequencys based on TDM
coffee_words <- data.frame("word"  = rownames(coffee_tdm),
"freq" = rowSums(coffee_tdm)
)
# Access bing lexicon: bing
bing <- get_sentiments("bing")
# Use data frame with text data
coffee_words <- coffee_words %>%
# With inner join, implement sentiment analysis using `bing`
inner_join(bing)
beep()
View(coffee_words)
coffee_words %>%
# Filter to only choose the words associated with sadness
filter(sentiment == "positive") %>%
# Group by word
group_by(word) %>%
# Use the summarize verb to find the mean frequency
summarize(freq = mean(freq)) %>%
# Arrange to sort in order of descending frequency
arrange(desc(freq))
dim(coffee_tdm)
coffee_tdm[1:10]
coffee_tdm[1:10,]
#install.packages("tm")
coffee_tweets_df<- read.csv("https://raw.githubusercontent.com/jaewilson07/Hello-World/master/Datasets/DataCamp/CoffeeTweets.txt",
stringsAsFactors = FALSE)
coffee_corpus <- VCorpus( DataframeSource(coffee_tweets_df) ,
readerControl = list(reader = custom_reader))
coffee_tdm <- TermDocumentMatrix(coffee_corpus) %>%
as.matrix()
coffee_tdm[1:10,]
#create aa dataframe of words and frequencys based on TDM
coffee_words <- data.frame("word"  = rownames(coffee_tdm),
"freq" = rowSums(coffee_tdm)
)
# Access bing lexicon: bing
bing <- get_sentiments("bing")
# Use data frame with text data
coffee_words <- coffee_words %>%
# With inner join, implement sentiment analysis using `bing`
inner_join(bing)
beep()
coffee_words$FirstChar <- substr(coffee_words$word, 1)
coffee_words$FirstChar <- substr(coffee_words$word, 1, 1)
coffee_words$FirstChar <- substr(coffee_words$word, 1, 1) %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
ungroup()
coffee_words%>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
ungroup() %>%
# Calculate the ratio of positive to negative words
mutate(ratio = positive / negative , state = reorder(state, ratio)) %>%
# Use aes() to put state on the x-axis and ratio on the y-axis
ggplot(aes(x = state, y = ratio)) +
# Make a plot with points using geom_point()
geom_point() +
coord_flip()
library(dplyr)
coffee_words%>%
# Group by two columns
group_by(FirstChar,sentiment)
coffee_words%>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq))
coffee_words%>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq)
library(tidyr)
coffee_words%>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
ungroup() %>%
# Calculate the ratio of positive to negative words
mutate(ratio = positive / negative , state = reorder(state, ratio)) %>%
# Use aes() to put state on the x-axis and ratio on the y-axis
ggplot(aes(x = state, y = ratio)) +
# Make a plot with points using geom_point()
geom_point() +
coord_flip()
coffee_words%>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
ungroup() %>%
coffee_words%>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
ungroup() %>%
# Calculate the ratio of positive to negative words
mutate(ratio = positive / negative,
FirstChar = reorder(FirstChar, ratio))
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment)
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq))
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq)
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
ungroup()
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
ungroup()
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq)
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
ungroup() %>%
# Calculate the ratio of positive to negative words
mutate(ratio = positive / negative,
FirstChar = reorder(FirstChar, ratio))
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
ungroup() %>%
# Calculate the ratio of positive to negative words
mutate(ratio = positive / negative,
FirstChar = reorder(FirstChar, ratio)) %>%
# Use aes() to put state on the x-axis and ratio on the y-axis
ggplot(aes(x = state, y = ratio))
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
ungroup() %>%
# Calculate the ratio of positive to negative words
mutate(ratio = positive / negative,
FirstChar = reorder(FirstChar, ratio)) %>%
# Use aes() to put state on the x-axis and ratio on the y-axis
ggplot(aes(x = FirstChar, y = ratio)) +
# Make a plot with points using geom_point()
geom_point()
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
ungroup() %>%
# Calculate the ratio of positive to negative words
mutate(ratio = positive / negative,
FirstChar = reorder(FirstChar, ratio)) %>%
# Use aes() to put state on the x-axis and ratio on the y-axis
ggplot(aes(x = FirstChar, y = ratio)) +
# Make a plot with points using geom_point()
geom_point() +
coord_flip()
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
#  ungroup() %>%
# Calculate the ratio of positive to negative words
mutate(ratio = positive / negative,
FirstChar = reorder(FirstChar, ratio)) %>%
# Use aes() to put state on the x-axis and ratio on the y-axis
ggplot(aes(x = FirstChar, y = ratio)) +
# Make a plot with points using geom_point()
geom_point() +
coord_flip()
coffee_words %>%
# Group by two columns
group_by(FirstChar,sentiment) %>%
# Use summarize to calculate the mean frequency for these groups
summarize(freq = mean(freq)) %>%
spread(sentiment, freq) %>%
ungroup() %>%
# Calculate the ratio of positive to negative words
mutate(ratio = positive / negative,
FirstChar = reorder(FirstChar, ratio)) %>%
# Use aes() to put state on the x-axis and ratio on the y-axis
ggplot(aes(x = FirstChar, y = ratio)) +
# Make a plot with points using geom_point()
geom_point() +
coord_flip()
load("D:/Users/JaeW/Dropbox (Personal)/Downloads/shakespeare.rda")
View(shakespeare)
load("D:/Users/JaeW/Dropbox (Personal)/School/UW/Hello-World/Datasets/DataCamp/shakespeare.rda")
shakespeare %>%
# Use count to find out how many titles/types there are
count(title, type)
shakespeare %>%
# Use count to find out how many titles/types there are
count(title, type)
shakespeare %>%
group_by (title)
shakespeaere_tidy <-shakespeare %>%
group_by (title) %>%
mutate(
linenumber = row_number()
) %>%
unnest_tokens(word, text)
head(shakespeaere_tidy)
shakespeare_tidy %>%
group_by(word) %>%
count()
shakespeaere_tidy %>%
group_by(word) %>%
count()
shakespeaere_tidy <-shakespeare %>%
group_by (title) %>%
mutate(
linenumber = row_number()
) %>%
unnest_tokens(word, text) %>%
ungroup()
shakespeaere_tidy %>%
count(word, sort = TRUE)
shakespeare_sentiment %>%
shakespeare_tidy inner_join(bing)
shakespeare_sentiment %>%
shakespeare_tidy %>% inner_join(bing)
shakespeare_sentiment<-
shakespeare_tidy %>% inner_join(bing)
shakespeare_sentiment<-
shakespeare_tidy %>% inner_join(bing)
shakespeare_tidy <-shakespeare %>%
group_by (title) %>%
mutate(
linenumber = row_number()
) %>%
unnest_tokens(word, text) %>%
ungroup()
shakespeare_tidy %>%
count(word, sort = TRUE)
shakespeare_sentiment<-
shakespeare_tidy %>% inner_join(bing)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(word)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(word) %>%
spread(title, sentiment)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(word) %>%
spread(sentiment)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(word, sentiment) %>%
spread(sentiment)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(word, sentiment) %>%
spread(sentiment)
shakespeare_sentiment %>%
group_by(title, sentiment)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(word, sentiment)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(word)
shakespeare_sentiment %>%
group_by(title) %>%
count(word)
shakespeare_sentiment %>%
group_by(title) %>%
count(sentiment)
shakespeare_sentiment %>%
group_by(title) %>%
count(sentiment) %>%
ungroup()
shakespeare_sentiment %>%
group_by(title) %>%
count(sentiment, word)
shakespeare_sentiment %>%
group_by(title) %>%
count(sentiment, word) %>%
ungroup()
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(word) %>%
ungroup()
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(title, sentiment) %>%
ungroup()
spread(sentiment)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(title, sentiment) %>%
ungroup() %>%
spread(sentiment)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(title, sentiment) %>%
spread(sentiment)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(title, sentiment) %>%
spread(sentiment) %>%
ungroup()
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(title, sentiment) %>%
ungroup() %>%
spread(sentiment)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(title, sentiment) %>%
ungroup() %>%
spread(title, sentiment)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(title, sentiment) %>%
ungroup()
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(title, sentiment) %>%
ungroup() %>%
spread( sentiment)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(title, sentiment) %>%
ungroup() %>%
spread( sentiment)
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(title, sentiment) %>%
spread( sentiment) %>%
ungroup()
n) %>%
shakespeare_sentiment %>%
group_by(title, sentiment) %>%
count(title, sentiment) %>%
spread( n) %>%
ungroup()
shakespeare_sentiment %>%
count(title, sentiment) %>%
str(bing)
str(bing)
unique(bing$sentiment)
shakespeare_sentiment %>%
count(title, sentiment)
shakespeare_sentiment
shakespeare_sentiment %>%
count(title, sentiment)
sentiment_counts <- shakespeare_sentiment %>%
# Count the number of words by title, type, and sentiment
count(title, type, sentiment)
sentiment_counts %>%
# Group by the titles of the plays
group_by(title) %>%
# Find the total number of words in each play
mutate(total = sum(n),
# Calculate the number of words divided by the total
percent = n/total )%>%
# Filter the results for only negative sentiment
filter(sentiment == "negative") %>%
arrange(percent)
sentiment_counts
word_counts <- tidy_shakespeare %>%
# Implement sentiment analysis using the "bing" lexicon
inner_join(get_sentiments("bing")) %>%
# Count by word and sentiment
count(word, sentiment)
#Top10
word_counts <- shakespeare_tidy %>%
# Implement sentiment analysis using the "bing" lexicon
inner_join(get_sentiments("bing")) %>%
# Count by word and sentiment
count(word, sentiment)
top_words <- word_counts %>%
# Group by sentiment
group_by(sentiment) %>%
# Take the top 10 for each sentiment
top_n(10) %>%
ungroup() %>%
# Make word a factor in order of n
mutate(word = reorder(word, n))
# Use aes() to put words on the x-axis and n on the y-axis
ggplot(top_words, aes(x = word, y = n, fill = sentiment)) +
# Make a bar chart with geom_col()
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free") +
coord_flip()
